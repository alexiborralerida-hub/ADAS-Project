{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Shape Modeling\n",
    "1) load the trained Instance Segmentation model\n",
    "2) predict lane masks\n",
    "3) fit mathematical equations (Polynomials/Splines) to the detected lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d853f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = r'C:\\ADAS_Project\\TUSimple_Small'\n",
    "TRAIN_SET_DIR = os.path.join(DATA_DIR, 'train_set')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, 'checkpoints/laneshape')\n",
    "\n",
    "# polynomial degree to fit\n",
    "degree = 2 \n",
    "\n",
    "# vertical: 30 meters / 288 pixels\n",
    "YM_PER_PIX = 30 / 288 \n",
    "# horizontal: 3.7 meters / 200 pixels (approx lane width in this view)\n",
    "XM_PER_PIX = 3.7 / 200 \n",
    "\n",
    "NUM_CLASSES = 6 \n",
    "IMG_HEIGHT = 288\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 5 \n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5*1e-4\n",
    "model_filename = f'best_model_instance_e{EPOCHS}_bs{BATCH_SIZE}_lr{LEARNING_RATE}.pth'\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, model_filename)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e310413",
   "metadata": {},
   "source": [
    "## 1. Model & Dataset Definitions\n",
    "Same as lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuSimpleDataset(Dataset):\n",
    "    def __init__(self, root_dir, processed_dir, json_files, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.processed_dir = processed_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for json_file in json_files:\n",
    "            json_path = os.path.join(root_dir, json_file)\n",
    "            if not os.path.exists(json_path):\n",
    "                continue\n",
    "                \n",
    "            with open(json_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                info = json.loads(line)\n",
    "                raw_file = info['raw_file']\n",
    "                mask_file = raw_file.replace('.jpg', '.png')\n",
    "                self.samples.append((raw_file, mask_file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_rel_path, mask_rel_path = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_rel_path)\n",
    "        mask_path = os.path.join(self.processed_dir, mask_rel_path)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        out = self.outc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c61880",
   "metadata": {},
   "source": [
    "## 2. Curve Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(x, y, degree):\n",
    "    try:\n",
    "        poly_coeffs = np.polyfit(y, x, degree)\n",
    "        poly_func = np.poly1d(poly_coeffs)\n",
    "        return poly_func, poly_coeffs\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None, None\n",
    "\n",
    "def fit_spline(x, y, s=0.0):\n",
    "    \"\"\"Fits a B-spline representation to the lane points.\"\"\"\n",
    "    try:\n",
    "        # Remove duplicates, sort by Y to ensure monotonicity if possible, but splprep handles general parametric\n",
    "        # splrep is for y=f(x), splprep is for parametric (x(t), y(t))\n",
    "        # For lanes, usually monotonic in Y. \n",
    "        \n",
    "        # Let's clean data first: unique points\n",
    "        points = np.column_stack((x, y))\n",
    "        _, unique_indices = np.unique(points, axis=0, return_index=True)\n",
    "        points = points[np.sort(unique_indices)]\n",
    "        \n",
    "        if len(points) < 4:\n",
    "            return None, None\n",
    "            \n",
    "        tck, u = splprep(points.T, u=None, s=s, per=0, k=min(3, len(points)-1))\n",
    "        return tck, u\n",
    "    except Exception as e:\n",
    "        # print(f\"Spline fit failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def measure_curvature(y_vals, poly_coeffs):\n",
    "    \"\"\"\n",
    "    Calculates the curvature of the polynomial at the bottom of the image.\n",
    "    Returns radius of curvature in meters.\n",
    "    \"\"\"\n",
    "    # Define y-value where we want radius of curvature (bottom of the image)\n",
    "    y_eval = np.max(y_vals)\n",
    "    \n",
    "    # Recalculate polynomials in world space\n",
    "    # x = ay^2 + by + c\n",
    "    # We need to scale the coefficients to meters\n",
    "    # A_m = A_pix * (xm / ym^2)\n",
    "    # B_m = B_pix * (xm / ym)\n",
    "    A = poly_coeffs[0]\n",
    "    B = poly_coeffs[1]\n",
    "    \n",
    "    A_m = A * (XM_PER_PIX / (YM_PER_PIX ** 2))\n",
    "    B_m = B * (XM_PER_PIX / YM_PER_PIX)\n",
    "    \n",
    "    # R = ((1 + (2Ay + B)^2)^1.5) / |2A|\n",
    "    R_curve = ((1 + (2*A_m*y_eval*YM_PER_PIX + B_m)**2)**1.5) / np.absolute(2*A_m)\n",
    "    return R_curve\n",
    "\n",
    "def measure_offset(poly_coeffs, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Calculates vehicle offset from the center of the lane.\n",
    "    Assumes camera is centered in the car.\n",
    "    \"\"\"\n",
    "    # Calculate x position at the bottom of the image\n",
    "    y_eval = img_height\n",
    "    x_lane_pix = poly_coeffs[0]*y_eval**2 + poly_coeffs[1]*y_eval + poly_coeffs[2]\n",
    "    \n",
    "    # Image center\n",
    "    x_center_pix = img_width / 2\n",
    "    \n",
    "    # Offset in pixels\n",
    "    offset_pix = x_lane_pix - x_center_pix\n",
    "    \n",
    "    # Convert to meters\n",
    "    offset_m = offset_pix * XM_PER_PIX\n",
    "    return offset_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b02a17",
   "metadata": {},
   "source": [
    "## 3. Execution & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6afc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_shapes(model_path, data_dir, processed_dir, json_files, num_visualize=5):\n",
    "    dataset = TuSimpleDataset(data_dir, processed_dir, json_files)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "    \n",
    "    model = UNet(n_channels=3, n_classes=NUM_CLASSES).to(device)\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "    else:\n",
    "        print(\"Model checkpoint not found. Please train the model first.\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(loader, desc=\"Fitting Shapes\"):\n",
    "            if count >= num_visualize: break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            # masks = masks.to(device) # We rely on prediction\n",
    "            \n",
    "            output = model(images)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred_mask = torch.argmax(probs, dim=1).squeeze(0).cpu().numpy()\n",
    "            \n",
    "            # Visualization Setup\n",
    "            img_np = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "            img_vis = img_np.copy()\n",
    "            img_vis = cv2.cvtColor(img_vis, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Color Palette for lanes\n",
    "            colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "            \n",
    "            # Iterate over each lane class\n",
    "            for cls_id in range(1, NUM_CLASSES):\n",
    "                # Extract pixels for this class\n",
    "                y_idx, x_idx = np.where(pred_mask == cls_id)\n",
    "                \n",
    "                if len(y_idx) < 50: continue # Skip if too few points\n",
    "                \n",
    "                color = colors[(cls_id - 1) % len(colors)]\n",
    "                \n",
    "                # --- Method 1: Polynomial Fit (x = ay^2 + by + c) ---\n",
    "                poly_func, coeffs = fit_poly(x_idx, y_idx, degree)\n",
    "                if poly_func:\n",
    "                    # Generate points for drawing\n",
    "                    plot_y = np.linspace(min(y_idx), max(y_idx), 100)\n",
    "                    plot_x = poly_func(plot_y)\n",
    "                    \n",
    "                    pts = np.array([np.transpose(np.vstack([plot_x, plot_y]))]).astype(np.int32)\n",
    "                    # Draw Poly Line\n",
    "                    cv2.polylines(img_vis, pts, isClosed=False, color=color, thickness=2)\n",
    "                    \n",
    "                    # Add Equation Text (Example for first lane)\n",
    "                    # cv2.putText(img_vis, f\"Lane {cls_id}: Poly\", (int(plot_x[0]), int(plot_y[0])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "                    # --- Measure Curvature & Offset ---\n",
    "                    r_curve = measure_curvature(plot_y, coeffs)\n",
    "                    offset = measure_offset(coeffs, IMG_HEIGHT, IMG_WIDTH)\n",
    "                    \n",
    "                    # Display Metrics\n",
    "                    label = f\"L{cls_id}: R={r_curve:.0f}m Off={offset:.2f}m\"\n",
    "                    cv2.putText(img_vis, label, (int(plot_x[-1])-50, int(plot_y[-1])-10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1, cv2.LINE_AA)\n",
    "\n",
    "                # --- Method 2: Spline Fit (Optional, commented out to avoid clutter) ---\n",
    "                # tck, u = fit_spline(x_idx, y_idx)\n",
    "                # if tck:\n",
    "                #     new_points = splev(np.linspace(0, 1, 100), tck)\n",
    "                #     pts_spline = np.array([np.transpose(np.vstack(new_points))]).astype(np.int32)\n",
    "                #     cv2.polylines(img_vis, pts_spline, isClosed=False, color=(255, 255, 255), thickness=1) # White for spline\n",
    "\n",
    "           \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f\"Lane Curve Fitting (Poly Degree 2)\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run\n",
    "json_files = ['label_data_0313.json', 'label_data_0531.json', 'label_data_0601.json']\n",
    "evaluate_shapes(BEST_MODEL_PATH, TRAIN_SET_DIR, PROCESSED_DATA_DIR, json_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
