{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54a1d35",
   "metadata": {},
   "source": [
    "## Lane Shape Modeling\n",
    "1) load the trained Instance Segmentation model\n",
    "2) predict lane masks\n",
    "3) fit mathematical equations (Polynomials/Splines) to the detected lanes.\n",
    "\n",
    "lane shape modeling improvements:\n",
    "- better filtering\n",
    "- applying to ground truth  \n",
    "- more metrics and comparisons\n",
    "- maybe also we can add spline method to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149d850",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d853f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = r'C:\\Users\\Alex\\Documents\\Clase\\Italia\\Segundo_ano\\ADAS\\Project\\TU_Simple_folder\\TUSimple'\n",
    "TRAIN_SET_DIR = os.path.join(DATA_DIR, 'train_set')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, r'processed\\instance')\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, r'checkpoints\\instance')\n",
    "\n",
    "# Polynomial degree to fit\n",
    "polynomial_degree = 2 \n",
    "\n",
    "# lane thickness (for masks and plots)\n",
    "lane_thickness=3\n",
    "tolerance= 2\n",
    "linear_lanefit_height = 50 # small blobs will be forced to have linear fittings \n",
    "\n",
    "NUM_CLASSES = 6 \n",
    "IMG_HEIGHT = 288\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 40 \n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "model_filename = f'best_model_instance_e{EPOCHS}_dropout_filter.pth'\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, model_filename)\n",
    "eval_filename = f'best_model_instance_e{EPOCHS}_dropout_filter.pth'\n",
    "EVAL_MODEL_PATH = os.path.join(CHECKPOINT_DIR, eval_filename)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e310413",
   "metadata": {},
   "source": [
    "## 2. Model & Dataset Definitions\n",
    "Same as lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuSimpleDataset(Dataset):\n",
    "    def __init__(self, root_dir, processed_dir, json_files, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.processed_dir = processed_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for json_file in json_files:\n",
    "            json_path = os.path.join(root_dir, json_file)\n",
    "            if not os.path.exists(json_path):\n",
    "                continue\n",
    "                \n",
    "            with open(json_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                info = json.loads(line)\n",
    "                raw_file = info['raw_file']\n",
    "                mask_file = raw_file.replace('.jpg', '.png')\n",
    "                img_path = os.path.join(self.root_dir, raw_file)\n",
    "                mask_path = os.path.join(self.processed_dir, mask_file)\n",
    "                self.samples.append((raw_file, mask_file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_rel_path, mask_rel_path = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_rel_path)\n",
    "        mask_path = os.path.join(self.processed_dir, mask_rel_path)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        out = self.outc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b02a17",
   "metadata": {},
   "source": [
    "## 3. Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6afc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_shapes(model_path, data_dir, processed_dir, json_files, polydegree):\n",
    "    # Number of random samples to visualize (for qualitative inspection)\n",
    "    num_visualize = 20\n",
    "    dataset = TuSimpleDataset(data_dir, processed_dir, json_files)\n",
    "    # No shuffling for evaluation between methods\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = UNet(n_channels=3, n_classes=NUM_CLASSES).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Colors for visualization (up to 5 lanes)\n",
    "    colors = [\n",
    "        (0, 0, 0),       # Background\n",
    "        (0, 255, 0),     # Lane 1\n",
    "        (255, 0, 0),     # Lane 2\n",
    "        (0, 0, 255),     # Lane 3\n",
    "        (255, 255, 0),   # Lane 4\n",
    "        (255, 0, 255)    # Lane 5\n",
    "    ]\n",
    "    \n",
    "\n",
    "    all_gt_mask_vs_fit = []\n",
    "    all_pred_mask_vs_fit = []\n",
    "    all_gt_fit_vs_pred_fit = []\n",
    "\n",
    "    print(f\"Starting evaluation... (Visualizing first {num_visualize} samples)\")\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(loader, desc=\"Evaluation\")):\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred_mask = torch.argmax(probs, dim=1).cpu().numpy()[0]\n",
    "            gt_mask_val = masks[0].cpu().numpy()\n",
    "            \n",
    "            img_np = (images[0].cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "            height, width = pred_mask.shape\n",
    "            \n",
    "            pred_polys = {}\n",
    "            gt_polys = {}\n",
    "            gt_eq_texts = []\n",
    "            pred_eq_texts = []\n",
    "            iou_texts = []\n",
    "\n",
    "            # Fitting loop \n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                # GT Fitting\n",
    "                lane_bool = (gt_mask_val == cls_idx)\n",
    "                if np.any(lane_bool):\n",
    "                    y_coords_gt, x_coords_gt = np.where(lane_bool)\n",
    "                    if len(y_coords_gt) > 20:\n",
    "                        gt_fit = np.polyfit(y_coords_gt, x_coords_gt, polydegree)\n",
    "                        min_y_gt = int(np.min(y_coords_gt))\n",
    "                        plot_y_gt = np.linspace(min_y_gt, height-1, num=(height-min_y_gt))\n",
    "                        gt_polys[cls_idx] = {'fit': gt_fit, 'y_range': plot_y_gt, 'y_min': min_y_gt}\n",
    "                        if i < num_visualize: gt_eq_texts.append(f'GT L{cls_idx}: x = {gt_fit[0]:.6f}y^2 + {gt_fit[1]:.6f}y + {gt_fit[2]:.6f}')\n",
    "                \n",
    "                # Pred Fitting\n",
    "                lane_mask_bool = (pred_mask == cls_idx)\n",
    "                if np.any(lane_mask_bool):\n",
    "                    y_coords, x_coords = np.where(lane_mask_bool)\n",
    "                    if len(y_coords) > 20:\n",
    "                        y_span = np.max(y_coords) - np.min(y_coords)\n",
    "                        deg = 1 if y_span < linear_lanefit_height else polydegree\n",
    "                        lane_fit = np.polyfit(y_coords, x_coords, deg)\n",
    "                        min_y = int(np.min(y_coords))\n",
    "                        plot_y_fit = np.linspace(min_y, height-1, num=(height-min_y))\n",
    "                        pred_polys[cls_idx] = {'fit': lane_fit, 'y_range': plot_y_fit, 'y_min': min_y}\n",
    "                        if i < num_visualize:\n",
    "                            if deg == 1: pred_eq_texts.append(f'L{cls_idx} (L): x = {lane_fit[0]:.6f}y + {lane_fit[1]:.6f}')\n",
    "                            else: pred_eq_texts.append(f'L{cls_idx} (Q): x = {lane_fit[0]:.6f}y^2 + {lane_fit[1]:.6f}y + {lane_fit[2]:.6f}')\n",
    "\n",
    "            # Metric Calculations and Sample Plots\n",
    "            sample_metrics = {\"gt_fit\": [], \"pred_fit\": [], \"comparison\": []}\n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                # GT Mask vs GT Fit\n",
    "                if cls_idx in gt_polys:\n",
    "                    g = gt_polys[cls_idx]; gt_lane_mask = (gt_mask_val == cls_idx)\n",
    "                    mask_gt_fit = np.zeros((height, width), dtype=np.uint8); mask_gt_fit_tol = np.zeros((height, width), dtype=np.uint8)\n",
    "                    px_g = np.polyval(g['fit'], g['y_range'])\n",
    "                    pts_g = np.array([np.transpose(np.vstack([px_g, g['y_range']]))]).astype(np.int32)\n",
    "                    cv2.polylines(mask_gt_fit, pts_g, False, 1, lane_thickness)\n",
    "                    cv2.polylines(mask_gt_fit_tol, pts_g, False, 1, lane_thickness + 2*tolerance)\n",
    "                    inter = np.sum(np.logical_and(gt_lane_mask > 0, mask_gt_fit_tol > 0))\n",
    "                    uni = np.sum(np.logical_or(gt_lane_mask > 0, mask_gt_fit > 0))\n",
    "                    iou = (inter / uni * 100) if uni > 0 else 0\n",
    "                    all_gt_mask_vs_fit.append(iou); sample_metrics[\"gt_fit\"].append((cls_idx, iou))\n",
    "                \n",
    "                # Pred Mask vs Pred Fit\n",
    "                if cls_idx in pred_polys:\n",
    "                    p = pred_polys[cls_idx]; pr_mask = (pred_mask == cls_idx)\n",
    "                    mask_pr_fit = np.zeros((height, width), dtype=np.uint8); mask_pr_fit_tol = np.zeros((height, width), dtype=np.uint8)\n",
    "                    px_p = np.polyval(p['fit'], p['y_range'])\n",
    "                    pts_p = np.array([np.transpose(np.vstack([px_p, p['y_range']]))]).astype(np.int32)\n",
    "                    cv2.polylines(mask_pr_fit, pts_p, False, 1, lane_thickness); cv2.polylines(mask_pr_fit_tol, pts_p, False, 1, lane_thickness + 2*tolerance)\n",
    "                    inter = np.sum(np.logical_and(pr_mask > 0, mask_pr_fit_tol > 0))\n",
    "                    uni = np.sum(np.logical_or(pr_mask > 0, mask_pr_fit > 0))\n",
    "                    iou = (inter / uni * 100) if uni > 0 else 0\n",
    "                    all_pred_mask_vs_fit.append(iou); sample_metrics[\"pred_fit\"].append((cls_idx, iou))\n",
    "\n",
    "                # GT Fit vs Pred Fit\n",
    "                if cls_idx in gt_polys:\n",
    "                    g = gt_polys[cls_idx]; m_g = np.zeros((height, width), dtype=np.uint8)\n",
    "                    px_g = np.polyval(g['fit'], g['y_range']); pts_g = np.array([np.transpose(np.vstack([px_g, g['y_range']]))]).astype(np.int32)\n",
    "                    cv2.polylines(m_g, pts_g, False, 1, lane_thickness)\n",
    "                    if cls_idx in pred_polys:\n",
    "                        p = pred_polys[cls_idx]; m_p = np.zeros((height, width), dtype=np.uint8); m_p_t = np.zeros((height, width), dtype=np.uint8)\n",
    "                        px_p = np.polyval(p['fit'], p['y_range']); pts_p = np.array([np.transpose(np.vstack([px_p, p['y_range']]))]).astype(np.int32)\n",
    "                        cv2.polylines(m_p, pts_p, False, 1, lane_thickness); cv2.polylines(m_p_t, pts_p, False, 1, lane_thickness + 2*tolerance)\n",
    "                        inter = np.sum(np.logical_and(m_g > 0, m_p_t > 0))\n",
    "                        uni = np.sum(np.logical_or(m_g > 0, m_p > 0))\n",
    "                        iou = (inter / uni * 100) if uni > 0 else 0\n",
    "                        all_gt_fit_vs_pred_fit.append(iou); sample_metrics[\"comparison\"].append((cls_idx, iou))\n",
    "                    else:\n",
    "                        all_gt_fit_vs_pred_fit.append(0.0); sample_metrics[\"comparison\"].append((cls_idx, 0.0))\n",
    "\n",
    "            if i < num_visualize:\n",
    "                print(f\"\\\\n--- Sample {i+1} Overlap Metrics ---\")\n",
    "                viz_gt_m = img_np.copy(); viz_pr_m = img_np.copy(); viz_gt_f = img_np.copy(); viz_pr_f = img_np.copy(); comp_viz = img_np.copy()\n",
    "                for cls_idx in range(1, NUM_CLASSES):\n",
    "                    color_rgb = colors[cls_idx]; color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])\n",
    "                    viz_gt_m[gt_mask_val == cls_idx] = color_bgr; viz_pr_m[pred_mask == cls_idx] = color_bgr\n",
    "                    if cls_idx in gt_polys:\n",
    "                        g = gt_polys[cls_idx]; pxg = np.polyval(g['fit'], g['y_range']); ptsg = np.array([np.transpose(np.vstack([pxg, g['y_range']]))]).astype(np.int32)\n",
    "                        cv2.polylines(viz_gt_f, ptsg, False, (255, 255, 255), 4); cv2.polylines(comp_viz, ptsg, False, (255, 255, 255), 4)\n",
    "                    if cls_idx in pred_polys:\n",
    "                        p = pred_polys[cls_idx]; pxp = np.polyval(p['fit'], p['y_range']); ptsp = np.array([np.transpose(np.vstack([pxp, p['y_range']]))]).astype(np.int32)\n",
    "                        cv2.polylines(viz_pr_f, ptsp, False, color_bgr, 4); cv2.polylines(comp_viz, ptsp, False, color_bgr, 4)\n",
    "\n",
    "                # Printing to console\n",
    "                for cid, val in sample_metrics[\"pred_fit\"]: print(f\"Lane {cid} Pred Mask vs Pred Fit IoU: {val:.2f}%\")\n",
    "                for cid, val in sample_metrics[\"gt_fit\"]: print(f\"Lane {cid} GT mask vs GT Fit: {val:.2f}%\")\n",
    "                for cid, val in sample_metrics[\"comparison\"]: \n",
    "                    print(f\"Lane {cid} Prediction Fit vs GT Fit: {val:.2f}%\")\n",
    "                    iou_texts.append(f\"L{cid} Pred v GT: {val:.1f}%\")\n",
    "\n",
    "                fig = plt.figure(figsize=(20, 15))\n",
    "                gs = fig.add_gridspec(3, 2)\n",
    "                ax1 = fig.add_subplot(gs[0, 0]); ax1.set_title(\"Ground Truth Mask\"); ax1.imshow(cv2.cvtColor(viz_gt_m, cv2.COLOR_BGR2RGB)); ax1.axis('off')\n",
    "                ax2 = fig.add_subplot(gs[0, 1]); ax2.set_title(\"Instance Segmentation Prediction\"); ax2.imshow(cv2.cvtColor(viz_pr_m, cv2.COLOR_BGR2RGB)); ax2.axis('off')\n",
    "                ax3 = fig.add_subplot(gs[1, 0]); ax3.set_title(\"Poly Fit (Ground Truth)\\n\" + \"\\n\".join(gt_eq_texts), fontsize=9); ax3.imshow(cv2.cvtColor(viz_gt_f, cv2.COLOR_BGR2RGB)); ax3.axis('off')\n",
    "                ax4 = fig.add_subplot(gs[1, 1]); ax4.set_title(\"Poly Fit (Prediction)\\n\" + \"\\n\".join(pred_eq_texts), fontsize=9); ax4.imshow(cv2.cvtColor(viz_pr_f, cv2.COLOR_BGR2RGB)); ax4.axis('off')\n",
    "                ax5 = fig.add_subplot(gs[2, :]); ax5.set_title(\"Fit Comparison (White=GT, Color=Pred)\\n\" + \" | \".join(iou_texts), fontsize=10); ax5.imshow(cv2.cvtColor(comp_viz, cv2.COLOR_BGR2RGB)); ax5.axis('off')\n",
    "                fig.suptitle(\"Lane 1: Green | Lane 2: Red | Lane 3: Blue | Lane 4: Yellow | Lane 5: Magenta\", fontsize=14, y=0.99)\n",
    "                plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Print Mean IoU Metrics\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"GLOBAL MEAN IoU METRICS\")\n",
    "    print(f\"Mean GT Mask vs GT Fit IoU:   {np.mean(all_gt_mask_vs_fit):.2f}%\")\n",
    "    print(f\"Mean Pred Mask vs Pred Fit IoU: {np.mean(all_pred_mask_vs_fit):.2f}%\")\n",
    "    print(f\"Mean GT Fit vs Pred Fit IoU:    {np.mean(all_gt_fit_vs_pred_fit):.2f}%\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b3203",
   "metadata": {},
   "source": [
    "## 4. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run\n",
    "json_files = ['label_data_0313.json', 'label_data_0531.json', 'label_data_0601.json']\n",
    "evaluate_shapes(EVAL_MODEL_PATH, TRAIN_SET_DIR, PROCESSED_DATA_DIR, json_files, polynomial_degree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
