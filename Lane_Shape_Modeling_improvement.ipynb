{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Shape Modeling\n",
    "1) load the trained Instance Segmentation model\n",
    "2) predict lane masks\n",
    "3) fit mathematical equations (Polynomials/Splines) to the detected lanes.\n",
    "\n",
    "lane shape modeling improvements:\n",
    "- better filtering\n",
    "- applying to ground truth  \n",
    "- more metrics and comparisons\n",
    "- maybe also we can add spline method to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d853f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = r'C:\\ADAS_Project\\TUSimple_Small'\n",
    "TRAIN_SET_DIR = os.path.join(DATA_DIR, 'train_set')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, r'processed\\instance')\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, r'checkpoints\\instance')\n",
    "eval_filename = f'best_model_instance_e20.pth'\n",
    "EVAL_MODEL_PATH = os.path.join(CHECKPOINT_DIR, eval_filename)\n",
    "# Polynomial degree to fit\n",
    "polynomial_degree = 2 \n",
    "\n",
    "NUM_CLASSES = 6 \n",
    "IMG_HEIGHT = 288\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 40 \n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5*1e-4\n",
    "model_filename = f'best_model_instance_e{EPOCHS}.pth'\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, model_filename)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e310413",
   "metadata": {},
   "source": [
    "## 1. Model & Dataset Definitions\n",
    "Same as lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuSimpleDataset(Dataset):\n",
    "    def __init__(self, root_dir, processed_dir, json_files, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.processed_dir = processed_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for json_file in json_files:\n",
    "            json_path = os.path.join(root_dir, json_file)\n",
    "            if not os.path.exists(json_path):\n",
    "                continue\n",
    "                \n",
    "            with open(json_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                info = json.loads(line)\n",
    "                raw_file = info['raw_file']\n",
    "                mask_file = raw_file.replace('.jpg', '.png')\n",
    "                img_path = os.path.join(self.root_dir, raw_file)\n",
    "                mask_path = os.path.join(self.processed_dir, mask_file)\n",
    "                self.samples.append((raw_file, mask_file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_rel_path, mask_rel_path = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_rel_path)\n",
    "        mask_path = os.path.join(self.processed_dir, mask_rel_path)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        out = self.outc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b02a17",
   "metadata": {},
   "source": [
    "## 3. Execution & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6afc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_shapes(model_path, data_dir, processed_dir, json_files, polydegree):\n",
    "    # Number of random samples to visualize (this function is for qualitative inspection)\n",
    "    num_visualize = 20\n",
    "    dataset = TuSimpleDataset(data_dir, processed_dir, json_files)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "    \n",
    "    model = UNet(n_channels=3, n_classes=NUM_CLASSES).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Colors for visualization (up to 5 lanes)\n",
    "    colors = [\n",
    "        (0, 0, 0),       # Background\n",
    "        (0, 255, 0),     # Lane 1\n",
    "        (255, 0, 0),     # Lane 2\n",
    "        (0, 0, 255),     # Lane 3\n",
    "        (255, 255, 0),   # Lane 4\n",
    "        (255, 0, 255)    # Lane 5\n",
    "    ]\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(loader, desc=\"Fitting Shapes\"):\n",
    "            if count >= num_visualize: break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            output = model(images)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred_mask = torch.argmax(probs, dim=1).cpu().numpy()[0]\n",
    "            \n",
    "            # Convert image tensor back to uint8 image for OpenCV drawing\n",
    "            img_np = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            viz_img = img_np.copy()\n",
    "            \n",
    "            # Fitting logic\n",
    "            height, width = pred_mask.shape\n",
    "            plot_y = np.linspace(0, height-1, height)\n",
    "            \n",
    "            pred_polys = {}\n",
    "            gt_polys = {}\n",
    "            \n",
    "             # Fit a curve independently for each lane class (1..5)\n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                # Binary mask for current lane class\n",
    "                lane_mask = (pred_mask == cls_idx).astype(np.uint8)\n",
    "                \n",
    "                # Blob filtering\n",
    "                # Keep only the largest blob if it is \"lane-like\" (large enough and tall enough)\n",
    "                lane_mask_uint8 = lane_mask.astype(np.uint8)\n",
    "                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(lane_mask_uint8, connectivity=8)\n",
    "                valid_lane = False\n",
    "                if num_labels > 1:\n",
    "\n",
    "                    # Find component with maximum area \n",
    "                    largest_idx = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "                    max_area = stats[largest_idx, cv2.CC_STAT_AREA]\n",
    "                    max_height = stats[largest_idx, cv2.CC_STAT_HEIGHT]\n",
    "                    \n",
    "                    # Thresholds to reject small or short components\n",
    "                    if max_area >= 1000 and max_height >= 50:\n",
    "                        lane_mask = (labels_im == largest_idx).astype(np.uint8)\n",
    "                        valid_lane = True\n",
    "                \n",
    "                if valid_lane:\n",
    "                    # Extract lane pixels as x, y coordinates\n",
    "                    y_coords, x_coords = np.where(lane_mask == 1)\n",
    "                    \n",
    "                    # Fit Polynomial\n",
    "                    lane_fit = np.polyfit(y_coords, x_coords, polydegree) \n",
    "                    print(f'Lane {cls_idx} Equation: x = {lane_fit[0]:.6f}*y^2 + {lane_fit[1]:.6f}*y + {lane_fit[2]:.6f}')\n",
    "\n",
    "                    # Generate points for plotting\n",
    "                    # Generate points for plotting (Constrained to detected range)\n",
    "                    min_y = int(np.min(y_coords))\n",
    "                    plot_y_fit = np.linspace(min_y, height-1, num=(height-min_y))\n",
    "                    # Store for comparison\n",
    "                    pred_polys[cls_idx] = {'fit': lane_fit, 'y_range': plot_y_fit}\n",
    "                    plot_x = np.polyval(lane_fit, plot_y_fit)\n",
    "                    \n",
    "                    # Draw onto the visualization image\n",
    "                    pts = np.array([np.transpose(np.vstack([plot_x, plot_y_fit]))])\n",
    "                    pts = pts.astype(np.int32)\n",
    "                    \n",
    "                    color = colors[cls_idx if cls_idx < len(colors) else 1]\n",
    "                    cv2.polylines(viz_img, pts, isClosed=False, color=(color[2], color[1], color[0]), thickness=5)\n",
    "                    \n",
    "            # Plot\n",
    "            fig, ax = plt.subplots(1, 4, figsize=(40, 8))\n",
    "            \n",
    "            # 1. Ground Truth Overlay & Fitting\n",
    "            gt_viz = img_np.copy()\n",
    "            gt_mask_val = masks[0].cpu().numpy()\n",
    "            \n",
    "            print(f\"\\n--- Ground Truth Fits for Sample {count+1} ---\")\n",
    "            \n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                # 1. Colorize the mask pixels\n",
    "                lane_bool = (gt_mask_val == cls_idx)\n",
    "                if np.any(lane_bool):\n",
    "                    color_rgb = colors[cls_idx if cls_idx < len(colors) else 1]\n",
    "                    gt_viz[lane_bool] = (color_rgb[2], color_rgb[1], color_rgb[0])\n",
    "                    \n",
    "                    # 2. Fit Polynomial to Ground Truth\n",
    "                    y_coords_gt, x_coords_gt = np.where(lane_bool)\n",
    "                    if len(y_coords_gt) > 20:\n",
    "                        gt_fit = np.polyfit(y_coords_gt, x_coords_gt, polydegree)\n",
    "                        print(f'GT Lane {cls_idx}: x = {gt_fit[0]:.6f}*y^2 + {gt_fit[1]:.6f}*y + {gt_fit[2]:.6f}')\n",
    "                        \n",
    "                        # Draw fit line (White)\n",
    "                        min_y_gt = int(np.min(y_coords_gt))\n",
    "                        plot_y_gt = np.linspace(min_y_gt, height-1, num=(height-min_y_gt))\n",
    "                        # Store for comparison\n",
    "                        gt_polys[cls_idx] = {'fit': gt_fit, 'y_range': plot_y_gt}\n",
    "                        plot_x_gt = np.polyval(gt_fit, plot_y_gt)\n",
    "                        \n",
    "                        pts_gt = np.array([np.transpose(np.vstack([plot_x_gt, plot_y_gt]))])\n",
    "                        pts_gt = pts_gt.astype(np.int32)\n",
    "                        cv2.polylines(gt_viz, pts_gt, isClosed=False, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "            ax[0].set_title(\"Ground Truth (Mask + Poly Fits)\")\n",
    "            ax[0].imshow(cv2.cvtColor(gt_viz, cv2.COLOR_BGR2RGB))\n",
    "            ax[0].axis('off')\n",
    "\n",
    "            # Compare Fits & Calculate Overlap\n",
    "            comp_viz = img_np.copy() # Background image\n",
    "            print(f\"--- Overlap Metrics (IoU with 5px Tolerance) ---\")\n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                has_pred = cls_idx in pred_polys\n",
    "                has_gt = cls_idx in gt_polys\n",
    "                \n",
    "                # Visualization Drawing (Thin lines for visual check)\n",
    "                if has_gt:\n",
    "                    g = gt_polys[cls_idx]\n",
    "                    px_g = np.polyval(g['fit'], g['y_range'])\n",
    "                    pts_g = np.array([np.transpose(np.vstack([px_g, g['y_range']]))]).astype(np.int32)\n",
    "                    cv2.polylines(comp_viz, pts_g, isClosed=False, color=(255, 255, 255), thickness=2)\n",
    "                \n",
    "                if has_pred:\n",
    "                    p = pred_polys[cls_idx]\n",
    "                    px_p = np.polyval(p['fit'], p['y_range'])\n",
    "                    pts_p = np.array([np.transpose(np.vstack([px_p, p['y_range']]))]).astype(np.int32)\n",
    "                    color_rgb = colors[cls_idx if cls_idx < len(colors) else 1]\n",
    "                    cv2.polylines(comp_viz, pts_p, isClosed=False, color=(color_rgb[2], color_rgb[1], color_rgb[0]), thickness=2)\n",
    "\n",
    "                # Metric Calculation\n",
    "                if has_gt:\n",
    "                    if has_pred:\n",
    "                        # Calculate IoU with Tolerance\n",
    "                        # Tolerance of 5px radius approx = line thickness of 10px\n",
    "                        mask_g = np.zeros((height, width), dtype=np.uint8)\n",
    "                        mask_p = np.zeros((height, width), dtype=np.uint8)\n",
    "                        \n",
    "                        # Ground Truth Mask\n",
    "                        g = gt_polys[cls_idx]\n",
    "                        px_g = np.polyval(g['fit'], g['y_range'])\n",
    "                        pts_g = np.array([np.transpose(np.vstack([px_g, g['y_range']]))]).astype(np.int32)\n",
    "                        cv2.polylines(mask_g, pts_g, isClosed=False, color=1, thickness=10)\n",
    "                        \n",
    "                        # Prediction Mask\n",
    "                        p = pred_polys[cls_idx]\n",
    "                        px_p = np.polyval(p['fit'], p['y_range'])\n",
    "                        pts_p = np.array([np.transpose(np.vstack([px_p, p['y_range']]))]).astype(np.int32)\n",
    "                        cv2.polylines(mask_p, pts_p, isClosed=False, color=1, thickness=10)\n",
    "                        \n",
    "                        intersection = np.sum((mask_g & mask_p))\n",
    "                        union = np.sum((mask_g | mask_p))\n",
    "                        iou = intersection / union if union > 0 else 0.0\n",
    "                        print(f\"Lane {cls_idx} Poly Fit Overlap (IoU): {iou*100:.2f}%\")\n",
    "                    else:\n",
    "                        # Present in GT, Missing in Pred\n",
    "                        print(f\"Lane {cls_idx} Poly Fit Overlap (IoU): 0.00% (Missed Detection)\")\n",
    "\n",
    "            # 2. Instance Segmentation Prediction (Projected)\n",
    "            pred_viz = img_np.copy()\n",
    "            for cls_idx in range(1, NUM_CLASSES):\n",
    "                # Use pred_mask which causes the drawing logic above\n",
    "                lane_bool = (pred_mask == cls_idx)\n",
    "                if np.any(lane_bool):\n",
    "                    color_rgb = colors[cls_idx if cls_idx < len(colors) else 1]\n",
    "                    pred_viz[lane_bool] = (color_rgb[2], color_rgb[1], color_rgb[0])\n",
    "            \n",
    "            ax[1].set_title(\"Instance Segmentation Prediction\")\n",
    "            ax[1].imshow(cv2.cvtColor(pred_viz, cv2.COLOR_BGR2RGB))\n",
    "            ax[1].axis('off')\n",
    "\n",
    "            # 3. Prediction + Polynomials\n",
    "            ax[2].set_title(\"Lane Shape Modeling (Polynomial Fit)\")\n",
    "            ax[2].imshow(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB))\n",
    "            ax[2].axis('off')\n",
    "\n",
    "            # 4. Comparison Overlay\n",
    "            ax[3].set_title(\"Fit Comparison (White=GT, Color=Pred)\")\n",
    "            ax[3].imshow(cv2.cvtColor(comp_viz, cv2.COLOR_BGR2RGB))\n",
    "            ax[3].axis('off')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run\n",
    "json_files = ['label_data_0313.json', 'label_data_0531.json', 'label_data_0601.json']\n",
    "evaluate_shapes(EVAL_MODEL_PATH, TRAIN_SET_DIR, PROCESSED_DATA_DIR, json_files, polynomial_degree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
